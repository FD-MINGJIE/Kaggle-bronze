{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# 导入库\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../input'\n",
    "SUBMISSIONS_PATH = './'\n",
    "# 使用原子的序号来对表示这些原子\n",
    "ATOMIC_NUMBERS = {\n",
    "    'H': 1,\n",
    "    'C': 6,\n",
    "    'N': 7,\n",
    "    'O': 8,\n",
    "    'F': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['champs-scalar-coupling', 'quantum-machine-9-qm9']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入库\n",
    "import os\n",
    "# 列出文件\n",
    "os.listdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.807602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.807404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.809303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.809502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    molecule_index  atom_index_0  atom_index_1  type  scalar_coupling_constant\n",
       "id                                                                            \n",
       "0   1               1             0             1JHC  84.807602               \n",
       "1   1               1             2             2JHH -11.257000               \n",
       "2   1               1             3             2JHH -11.254800               \n",
       "3   1               1             4             2JHH -11.254300               \n",
       "4   1               2             0             1JHC  84.807404               \n",
       "5   1               2             3             2JHH -11.254100               \n",
       "6   1               2             4             2JHH -11.254800               \n",
       "7   1               3             0             1JHC  84.809303               \n",
       "8   1               3             4             2JHH -11.254300               \n",
       "9   1               4             0             1JHC  84.809502               "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集的数据类型设置\n",
    "train_dtypes = {\n",
    "    'molecule_name': 'category',\n",
    "    'atom_index_0': 'int8',\n",
    "    'atom_index_1': 'int8',\n",
    "    'type': 'category',\n",
    "    'scalar_coupling_constant': 'float32'\n",
    "}\n",
    "# 读取训练集文件\n",
    "train_csv = pd.read_csv(f'{DATA_PATH}/champs-scalar-coupling/train.csv', index_col='id', dtype=train_dtypes)\n",
    "# 将molecule_name的格式从dsgdb9nsd_xx改成xx方面处理\n",
    "train_csv['molecule_index'] = train_csv.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "train_csv = train_csv[['molecule_index', 'atom_index_0', 'atom_index_1', 'type', 'scalar_coupling_constant']]\n",
    "#打印前10个元素\n",
    "train_csv.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取需要提交的文件\n",
    "submission_csv = pd.read_csv(f'{DATA_PATH}/champs-scalar-coupling/sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4658147</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658148</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658149</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3JHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658150</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658151</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658152</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658153</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658154</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658155</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2JHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658156</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         molecule_index  atom_index_0  atom_index_1  type\n",
       "id                                                       \n",
       "4658147  4               2             0             2JHC\n",
       "4658148  4               2             1             1JHC\n",
       "4658149  4               2             3             3JHH\n",
       "4658150  4               3             0             1JHC\n",
       "4658151  4               3             1             2JHC\n",
       "4658152  15              3             0             1JHC\n",
       "4658153  15              3             2             3JHC\n",
       "4658154  15              3             4             2JHH\n",
       "4658155  15              3             5             2JHH\n",
       "4658156  15              4             0             1JHC"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取测试文件\n",
    "test_csv = pd.read_csv(f'{DATA_PATH}/champs-scalar-coupling/test.csv', index_col='id', dtype=train_dtypes)\n",
    "test_csv['molecule_index'] = test_csv['molecule_name'].str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "test_csv = test_csv[['molecule_index', 'atom_index_0', 'atom_index_1', 'type']]\n",
    "test_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index</th>\n",
       "      <th>atom</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.040426</td>\n",
       "      <td>1.024108</td>\n",
       "      <td>0.062564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017257</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>-0.027377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>1.358745</td>\n",
       "      <td>-0.028758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.520278</td>\n",
       "      <td>1.343532</td>\n",
       "      <td>-0.775543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.034360</td>\n",
       "      <td>0.977540</td>\n",
       "      <td>0.007602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   molecule_index  atom_index  atom         x         y         z\n",
       "0  1               0           6    -0.012698  1.085804  0.008001\n",
       "1  1               1           1     0.002150 -0.006031  0.001976\n",
       "2  1               2           1     1.011731  1.463751  0.000277\n",
       "3  1               3           1    -0.540815  1.447527 -0.876644\n",
       "4  1               4           1    -0.523814  1.437933  0.906397\n",
       "5  2               0           7    -0.040426  1.024108  0.062564\n",
       "6  2               1           1     0.017257  0.012545 -0.027377\n",
       "7  2               2           1     0.915789  1.358745 -0.028758\n",
       "8  2               3           1    -0.520278  1.343532 -0.775543\n",
       "9  3               0           8    -0.034360  0.977540  0.007602"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 结构数据类型\n",
    "structures_dtypes = {\n",
    "    'molecule_name': 'category',\n",
    "    'atom_index': 'int8',\n",
    "    'atom': 'category',\n",
    "    'x': 'float32',\n",
    "    'y': 'float32',\n",
    "    'z': 'float32'\n",
    "}\n",
    "structures_csv = pd.read_csv(f'{DATA_PATH}/champs-scalar-coupling/structures.csv', dtype=structures_dtypes)\n",
    "structures_csv['molecule_index'] = structures_csv.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "structures_csv = structures_csv[['molecule_index', 'atom_index', 'atom', 'x', 'y', 'z']]\n",
    "structures_csv['atom'] = structures_csv['atom'].replace(ATOMIC_NUMBERS).astype('int8')\n",
    "structures_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (2358657, 6)\n",
      "Total:  42455954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index             128    \n",
       "molecule_index    9434628\n",
       "atom_index        2358657\n",
       "atom              2358657\n",
       "x                 9434628\n",
       "y                 9434628\n",
       "z                 9434628\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Shape: ', structures_csv.shape)\n",
    "print('Total: ', structures_csv.memory_usage().sum())\n",
    "structures_csv.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Distance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据耦合键的类型，提取特定的数据\n",
    "def build_type_dataframes(base, structures, coupling_type):\n",
    "    base = base[base['type'] == coupling_type].drop('type', axis=1).copy()\n",
    "    base = base.reset_index()\n",
    "    base['id'] = base['id'].astype('int32')\n",
    "    structures = structures[structures['molecule_index'].isin(base['molecule_index'])]\n",
    "    return base, structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 降低内存使用，感觉每个变量的取值范围将其动态改变类型\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将Categorical类型的数据变成热编码数据\n",
    "def dummies(df, list_cols):\n",
    "    for col in list_cols:\n",
    "        df_dummies = pd.get_dummies(df[col], drop_first=True, \n",
    "                                    prefix=(str(col)))\n",
    "        df = pd.concat([df, df_dummies], axis=1)\n",
    "    return df\n",
    "\n",
    "# 添加QM9特征\n",
    "def add_qm9_features(df):\n",
    "    # 读取qm9数据\n",
    "    data_qm9 = pd.read_pickle('../input/quantum-machine-9-qm9/data.covs.pickle')\n",
    "    # 抛去一些无用的和重复的特征\n",
    "    to_drop = ['type', \n",
    "               'linear', \n",
    "               'atom_index_0', \n",
    "               'atom_index_1', \n",
    "               'scalar_coupling_constant', \n",
    "               'U', 'G', 'H', \n",
    "               'mulliken_mean', 'r2', 'U0']\n",
    "    data_qm9 = data_qm9.drop(columns = to_drop, axis=1)\n",
    "    # 减少内存\n",
    "    data_qm9 = reduce_mem_usage(data_qm9,verbose=False)\n",
    "    # 将molecule_index改成\n",
    "    data_qm9['molecule_index'] = data_qm9.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "    data_qm9=data_qm9.drop(columns=['molecule_name'])\n",
    "    # 将qm9特征加入到df里面去\n",
    "    df = pd.merge(df, data_qm9, how='left', on=['molecule_index','id'])\n",
    "    # 抛去molecule_index,id这个对我们预测没啥帮助，此时df已经是最后的训练集或者测试集，特征工程已经处理结束\n",
    "    df=df.drop(columns=['molecule_index','id'])\n",
    "    del data_qm9\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从structure根据molecule_index和atom_index来得到得到atom的坐标\n",
    "def add_coordinates(base, structures, index):\n",
    "    df = pd.merge(base, structures, how='inner',\n",
    "                  left_on=['molecule_index', f'atom_index_{index}'],\n",
    "                  right_on=['molecule_index', 'atom_index']).drop(['atom_index'], axis=1)\n",
    "    df = df.rename(columns={\n",
    "        'atom': f'atom_{index}',\n",
    "        'x': f'x_{index}',\n",
    "        'y': f'y_{index}',\n",
    "        'z': f'z_{index}'\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加原子的信息\n",
    "def add_atoms(base, atoms):\n",
    "    df = pd.merge(base, atoms, how='inner',\n",
    "                  on=['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 除了原有的atom_index_0和atom_index_1的那些行不加进去，其它的都加进去\n",
    "def merge_all_atoms(base, structures):\n",
    "    df = pd.merge(base, structures, how='left',\n",
    "                  left_on=['molecule_index'],\n",
    "                  right_on=['molecule_index'])\n",
    "    df = df[(df.atom_index_0 != df.atom_index) & (df.atom_index_1 != df.atom_index)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到中心点的坐标\n",
    "def add_center(df):\n",
    "    df['x_c'] = ((df['x_1'] + df['x_0']) * np.float32(0.5))\n",
    "    df['y_c'] = ((df['y_1'] + df['y_0']) * np.float32(0.5))\n",
    "    df['z_c'] = ((df['z_1'] + df['z_0']) * np.float32(0.5))\n",
    "\n",
    "# 得到到中心点的距离\n",
    "def add_distance_to_center(df):\n",
    "    df['d_c'] = ((\n",
    "        (df['x_c'] - df['x'])**np.float32(2) +\n",
    "        (df['y_c'] - df['y'])**np.float32(2) + \n",
    "        (df['z_c'] - df['z'])**np.float32(2)\n",
    "    )**np.float32(0.5))\n",
    "\n",
    "# 计算下标suffix1,和suffix2之间距离\n",
    "def add_distance_between(df, suffix1, suffix2):\n",
    "    df[f'd_{suffix1}_{suffix2}'] = ((\n",
    "        (df[f'x_{suffix1}'] - df[f'x_{suffix2}'])**np.float32(2) +\n",
    "        (df[f'y_{suffix1}'] - df[f'y_{suffix2}'])**np.float32(2) + \n",
    "        (df[f'z_{suffix1}'] - df[f'z_{suffix2}'])**np.float32(2)\n",
    "    )**np.float32(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算各个原子间的距离\n",
    "def add_distances(df):\n",
    "    n_atoms = 1 + max([int(c.split('_')[1]) for c in df.columns if c.startswith('x_')])\n",
    "    \n",
    "    for i in range(1, n_atoms):\n",
    "        for vi in range(min(4, i)):\n",
    "            add_distance_between(df, i, vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加一个特征，该特征为molecule_index的分子对应原子的个数\n",
    "def add_n_atoms(base, structures):\n",
    "    dfs = structures['molecule_index'].value_counts().rename('n_atoms').to_frame()\n",
    "    return pd.merge(base, dfs, left_on='molecule_index', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建需要跑的数据集\n",
    "def build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=10):\n",
    "    # 得到base，structures\n",
    "    base, structures = build_type_dataframes(some_csv, structures_csv, coupling_type)\n",
    "    # 添加原子1，原子2的坐标\n",
    "    base = add_coordinates(base, structures, 0)\n",
    "    base = add_coordinates(base, structures, 1)\n",
    "    # 扔掉原子1，2的序号的两列\n",
    "    base = base.drop(['atom_0', 'atom_1'], axis=1)\n",
    "    #  扔掉id这一列\n",
    "    atoms = base.drop('id', axis=1).copy()\n",
    "    \n",
    "    # 如果有scalar_coupling_constant这一列，则丢掉，scalar_coupling_constant这列是y的值\n",
    "    if 'scalar_coupling_constant' in some_csv:\n",
    "        atoms = atoms.drop(['scalar_coupling_constant'], axis=1)\n",
    "        \n",
    "    # 添加中心点\n",
    "    add_center(atoms)\n",
    "    \n",
    "    # 删掉原子1，原子2的坐标，现在用中心点来替代\n",
    "    atoms = atoms.drop(['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1'], axis=1)\n",
    "\n",
    "    # 合并所有的原子\n",
    "    atoms = merge_all_atoms(atoms, structures)\n",
    "    \n",
    "    # 对所有的原子添加到中心的距离\n",
    "    add_distance_to_center(atoms)\n",
    "    \n",
    "    # 删除中心点位置\n",
    "    atoms = atoms.drop(['x_c', 'y_c', 'z_c', 'atom_index'], axis=1)\n",
    "    \n",
    "    # 按照molecule_index,atom_index_0,atom_index_1,d_c来对atoms进行排序\n",
    "    atoms.sort_values(['molecule_index', 'atom_index_0', 'atom_index_1', 'd_c'], inplace=True)\n",
    "    \n",
    "    # 提取原子小于n_atoms的分子\n",
    "    atom_groups = atoms.groupby(['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    atoms['num'] = atom_groups.cumcount() + 2\n",
    "    atoms = atoms.drop(['d_c'], axis=1)\n",
    "    atoms = atoms[atoms['num'] < n_atoms]\n",
    "\n",
    "    # 对索引设置并通过molecule_index展开\n",
    "    atoms = atoms.set_index(['molecule_index', 'atom_index_0', 'atom_index_1', 'num']).unstack()\n",
    "    atoms.columns = [f'{col[0]}_{col[1]}' for col in atoms.columns]\n",
    "    atoms = atoms.reset_index()\n",
    "    \n",
    "    # 转回int8的类型\n",
    "    for col in atoms.columns:\n",
    "        if col.startswith('atom_'):\n",
    "            atoms[col] = atoms[col].fillna(0).astype('int8')\n",
    "            \n",
    "    # 转类型\n",
    "    atoms['molecule_index'] = atoms['molecule_index'].astype('int32')\n",
    "    \n",
    "    # 添加原子信息\n",
    "    full = add_atoms(base, atoms)\n",
    "    \n",
    "    # 添加距离\n",
    "    add_distances(full)\n",
    "    \n",
    "    # 根据id来进行重新排序\n",
    "    full.sort_values('id', inplace=True)\n",
    "    \n",
    "    return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成需要使用的label\n",
    "def take_n_atoms(df, n_atoms, four_start=4):\n",
    "    labels = []\n",
    "    for i in range(2, n_atoms):\n",
    "        label = f'atom_{i}'\n",
    "        labels.append(label)\n",
    "\n",
    "    for i in range(n_atoms):\n",
    "        num = min(i, 4) if i < four_start else 4\n",
    "        for j in range(num):\n",
    "            labels.append(f'd_{i}_{j}')\n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        labels.append('scalar_coupling_constant')\n",
    "    labels=['id','molecule_index']+labels\n",
    "    return df[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成x,y数据\n",
    "def build_x_y_data(some_csv, coupling_type, n_atoms):\n",
    "    full = build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=n_atoms)\n",
    "    \n",
    "    df = take_n_atoms(full, n_atoms)\n",
    "    df = df.fillna(0)\n",
    "    df=add_qm9_features(df)\n",
    "    print(df.columns)\n",
    "    \n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        X_data = df.drop(['scalar_coupling_constant'], axis=1).values.astype('float32')\n",
    "        y_data = df['scalar_coupling_constant'].values.astype('float32')\n",
    "    else:\n",
    "        X_data = df.values.astype('float32')\n",
    "        y_data = None\n",
    "    \n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check LightGBM with the smallest type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'd_1_0', 'd_2_0',\n",
      "       'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1', 'd_4_2', 'd_4_3',\n",
      "       'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1', 'd_6_2', 'd_6_3',\n",
      "       'scalar_coupling_constant', 'rc_A', 'rc_B', 'rc_C', 'mu', 'alpha',\n",
      "       'homo', 'lumo', 'gap', 'zpve', 'Cv', 'freqs_min', 'freqs_max',\n",
      "       'freqs_mean', 'mulliken_min', 'mulliken_max', 'mulliken_atom_0',\n",
      "       'mulliken_atom_1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 拿出1JHN进行一个测试\n",
    "tx,ty=build_x_y_data(train_csv, '1JHN', 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't calculate distances for `d_0_x`, `d_1_1`, `d_2_2`, `d_2_3`, `d_3_3` because we already have them in later atoms(`d_0_1` == `d_1_0`) or they are equal to zeros(e.g. `d_1_1`, `d_2_2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb的参数\n",
    "LGB_PARAMS = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 128,\n",
    "    'min_child_samples': 79,\n",
    "    'max_depth': 9,\n",
    "    'subsample_freq': 1,\n",
    "    'subsample': 0.9,\n",
    "    'bagging_seed': 11,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.3,\n",
    "    'colsample_bytree': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad score for such a simple set of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_for_one_coupling_type(coupling_type, submission,oof_sub, n_atoms, n_folds=5,n_depth=9, n_splits=5, random_state=128):\n",
    "    print(f'*** Training Model for {coupling_type} ***')\n",
    "    # 训练集\n",
    "    X_data, y_data = build_x_y_data(train_csv, coupling_type, n_atoms)\n",
    "    # 测试集\n",
    "    X_test, _ = build_x_y_data(test_csv, coupling_type, n_atoms)\n",
    "    # 需要提交的数据\n",
    "    y_pred = np.zeros(X_test.shape[0], dtype='float32')\n",
    "    # oof本来使用了stacking的，后来没用上\n",
    "    oof = np.zeros(X_data.shape[0],dtype='float32')\n",
    "    # 交叉验证的分数\n",
    "    cv_score = 0\n",
    "  \n",
    "    # K折交叉验证\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X_data, y_data)):\n",
    "        if fold >= n_folds:\n",
    "            break\n",
    "\n",
    "        X_train, X_val = X_data[train_index], X_data[val_index]\n",
    "        y_train, y_val = y_data[train_index], y_data[val_index]\n",
    "        # 设置观测的指标\n",
    "        LGB_PARAMS['max_depth']=n_depth\n",
    "        if coupling_type == '1JHN':\n",
    "            iterations=4000\n",
    "        elif coupling_type == '1JHC':\n",
    "            iterations=6000\n",
    "        else:\n",
    "            iterations=4000\n",
    "        \n",
    "        # LGB搭建模型，并开始预测\n",
    "        model = LGBMRegressor(**LGB_PARAMS, n_estimators=iterations, n_jobs = -1)\n",
    "        model.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='mae',verbose=1000,early_stopping_rounds=200)\n",
    "        \n",
    "        # lgb对验证集的预测结果\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        # 得到验证集的分数\n",
    "        val_score = np.log(mean_absolute_error(y_val, y_val_pred))\n",
    "        print(f'{coupling_type} Fold {fold}, logMAE: {val_score}')\n",
    "        oof[val_index]=y_val_pred\n",
    "        cv_score += val_score / n_folds\n",
    "        # lgb对测试集的预测结果\n",
    "        y_pred += model.predict(X_test) / n_folds\n",
    "        \n",
    "        \n",
    "    submission.loc[test_csv['type'] == coupling_type, 'scalar_coupling_constant'] = y_pred\n",
    "    oof_sub.loc[train_csv['type'] == coupling_type, 'scalar_coupling_constant'] = oof\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training Model for 1JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant', 'rc_A', 'rc_B', 'rc_C', 'mu', 'alpha',\n",
      "       'homo', 'lumo', 'gap', 'zpve', 'Cv', 'freqs_min', 'freqs_max',\n",
      "       'freqs_mean', 'mulliken_min', 'mulliken_max', 'mulliken_atom_0',\n",
      "       'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3', 'rc_A',\n",
      "       'rc_B', 'rc_C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'zpve', 'Cv',\n",
      "       'freqs_min', 'freqs_max', 'freqs_mean', 'mulliken_min', 'mulliken_max',\n",
      "       'mulliken_atom_0', 'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.125107\tvalid_1's l1: 0.325002\n",
      "[2000]\ttraining's l1: 0.0490344\tvalid_1's l1: 0.310772\n",
      "[3000]\ttraining's l1: 0.018866\tvalid_1's l1: 0.306771\n",
      "[4000]\ttraining's l1: 0.00748242\tvalid_1's l1: 0.305784\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.00748242\tvalid_1's l1: 0.305784\n",
      "1JHN Fold 0, logMAE: -1.1848766986931873\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.119199\tvalid_1's l1: 0.320323\n",
      "[2000]\ttraining's l1: 0.047716\tvalid_1's l1: 0.305861\n",
      "[3000]\ttraining's l1: 0.0187953\tvalid_1's l1: 0.302488\n",
      "[4000]\ttraining's l1: 0.00749444\tvalid_1's l1: 0.301422\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.00749444\tvalid_1's l1: 0.301422\n",
      "1JHN Fold 1, logMAE: -1.199242370766606\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.117254\tvalid_1's l1: 0.326422\n",
      "[2000]\ttraining's l1: 0.0458495\tvalid_1's l1: 0.31276\n",
      "[3000]\ttraining's l1: 0.0174269\tvalid_1's l1: 0.309221\n",
      "[4000]\ttraining's l1: 0.00684003\tvalid_1's l1: 0.308411\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.00684003\tvalid_1's l1: 0.308411\n",
      "1JHN Fold 2, logMAE: -1.1763232950413265\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.117213\tvalid_1's l1: 0.335299\n",
      "[2000]\ttraining's l1: 0.0434761\tvalid_1's l1: 0.321168\n",
      "[3000]\ttraining's l1: 0.0163853\tvalid_1's l1: 0.317981\n",
      "[4000]\ttraining's l1: 0.00670861\tvalid_1's l1: 0.317027\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.00670861\tvalid_1's l1: 0.317027\n",
      "1JHN Fold 3, logMAE: -1.1487681686849807\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.13253\tvalid_1's l1: 0.319131\n",
      "[2000]\ttraining's l1: 0.060288\tvalid_1's l1: 0.303733\n",
      "[3000]\ttraining's l1: 0.0275485\tvalid_1's l1: 0.299496\n",
      "[4000]\ttraining's l1: 0.0125618\tvalid_1's l1: 0.298156\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0125618\tvalid_1's l1: 0.298156\n",
      "1JHN Fold 4, logMAE: -1.210137883460043\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.120474\tvalid_1's l1: 0.32097\n",
      "[2000]\ttraining's l1: 0.047613\tvalid_1's l1: 0.306792\n",
      "[3000]\ttraining's l1: 0.0180946\tvalid_1's l1: 0.302961\n",
      "[4000]\ttraining's l1: 0.0071438\tvalid_1's l1: 0.301945\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0071438\tvalid_1's l1: 0.301945\n",
      "1JHN Fold 5, logMAE: -1.1975103026015623\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.128897\tvalid_1's l1: 0.329152\n",
      "[2000]\ttraining's l1: 0.0543492\tvalid_1's l1: 0.313978\n",
      "[3000]\ttraining's l1: 0.0225379\tvalid_1's l1: 0.310129\n",
      "[4000]\ttraining's l1: 0.00918813\tvalid_1's l1: 0.308777\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.00918813\tvalid_1's l1: 0.308777\n",
      "1JHN Fold 6, logMAE: -1.1751354833314243\n",
      "*** Training Model for 1JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'd_1_0', 'd_2_0', 'd_2_1',\n",
      "       'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0',\n",
      "       'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0',\n",
      "       'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0',\n",
      "       'd_9_1', 'd_9_2', 'd_9_3', 'd_10_0', 'd_10_1', 'd_10_2', 'd_10_3',\n",
      "       'd_11_0', 'd_11_1', 'd_11_2', 'd_11_3', 'd_12_0', 'd_12_1', 'd_12_2',\n",
      "       'd_12_3', 'scalar_coupling_constant', 'rc_A', 'rc_B', 'rc_C', 'mu',\n",
      "       'alpha', 'homo', 'lumo', 'gap', 'zpve', 'Cv', 'freqs_min', 'freqs_max',\n",
      "       'freqs_mean', 'mulliken_min', 'mulliken_max', 'mulliken_atom_0',\n",
      "       'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'd_1_0', 'd_2_0', 'd_2_1',\n",
      "       'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0',\n",
      "       'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0',\n",
      "       'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0',\n",
      "       'd_9_1', 'd_9_2', 'd_9_3', 'd_10_0', 'd_10_1', 'd_10_2', 'd_10_3',\n",
      "       'd_11_0', 'd_11_1', 'd_11_2', 'd_11_3', 'd_12_0', 'd_12_1', 'd_12_2',\n",
      "       'd_12_3', 'rc_A', 'rc_B', 'rc_C', 'mu', 'alpha', 'homo', 'lumo', 'gap',\n",
      "       'zpve', 'Cv', 'freqs_min', 'freqs_max', 'freqs_mean', 'mulliken_min',\n",
      "       'mulliken_max', 'mulliken_atom_0', 'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.589123\tvalid_1's l1: 0.743743\n",
      "[2000]\ttraining's l1: 0.42878\tvalid_1's l1: 0.658304\n",
      "[3000]\ttraining's l1: 0.337431\tvalid_1's l1: 0.619217\n",
      "[4000]\ttraining's l1: 0.275213\tvalid_1's l1: 0.597063\n",
      "[5000]\ttraining's l1: 0.229274\tvalid_1's l1: 0.582638\n",
      "[6000]\ttraining's l1: 0.193371\tvalid_1's l1: 0.572198\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[6000]\ttraining's l1: 0.193371\tvalid_1's l1: 0.572198\n",
      "1JHC Fold 0, logMAE: -0.5582702013957538\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.59039\tvalid_1's l1: 0.745373\n",
      "[2000]\ttraining's l1: 0.429812\tvalid_1's l1: 0.661308\n",
      "[3000]\ttraining's l1: 0.338736\tvalid_1's l1: 0.623433\n",
      "[4000]\ttraining's l1: 0.276416\tvalid_1's l1: 0.600791\n",
      "[5000]\ttraining's l1: 0.230221\tvalid_1's l1: 0.586124\n",
      "[6000]\ttraining's l1: 0.194625\tvalid_1's l1: 0.575983\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[6000]\ttraining's l1: 0.194625\tvalid_1's l1: 0.575983\n",
      "1JHC Fold 1, logMAE: -0.5516773827510522\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.590132\tvalid_1's l1: 0.74538\n",
      "[2000]\ttraining's l1: 0.429761\tvalid_1's l1: 0.661794\n",
      "[3000]\ttraining's l1: 0.338511\tvalid_1's l1: 0.623739\n",
      "[4000]\ttraining's l1: 0.275766\tvalid_1's l1: 0.601298\n",
      "[5000]\ttraining's l1: 0.229404\tvalid_1's l1: 0.586512\n",
      "[6000]\ttraining's l1: 0.193605\tvalid_1's l1: 0.576289\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[6000]\ttraining's l1: 0.193605\tvalid_1's l1: 0.576289\n",
      "1JHC Fold 2, logMAE: -0.5511462350265824\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.590416\tvalid_1's l1: 0.740438\n",
      "[2000]\ttraining's l1: 0.429763\tvalid_1's l1: 0.655475\n",
      "[3000]\ttraining's l1: 0.338353\tvalid_1's l1: 0.616998\n",
      "[4000]\ttraining's l1: 0.275798\tvalid_1's l1: 0.594396\n",
      "[5000]\ttraining's l1: 0.229294\tvalid_1's l1: 0.579476\n",
      "[6000]\ttraining's l1: 0.193572\tvalid_1's l1: 0.569332\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[6000]\ttraining's l1: 0.193572\tvalid_1's l1: 0.569332\n",
      "1JHC Fold 3, logMAE: -0.5632919258714749\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.589561\tvalid_1's l1: 0.745115\n",
      "[2000]\ttraining's l1: 0.428993\tvalid_1's l1: 0.658836\n",
      "[3000]\ttraining's l1: 0.338181\tvalid_1's l1: 0.620469\n",
      "[4000]\ttraining's l1: 0.275444\tvalid_1's l1: 0.597653\n",
      "[5000]\ttraining's l1: 0.229312\tvalid_1's l1: 0.582395\n",
      "[6000]\ttraining's l1: 0.193457\tvalid_1's l1: 0.571801\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[6000]\ttraining's l1: 0.193457\tvalid_1's l1: 0.571801\n",
      "1JHC Fold 4, logMAE: -0.5589637533312671\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.589429\tvalid_1's l1: 0.744432\n",
      "[2000]\ttraining's l1: 0.428422\tvalid_1's l1: 0.659495\n",
      "[3000]\ttraining's l1: 0.337333\tvalid_1's l1: 0.621857\n",
      "[4000]\ttraining's l1: 0.275037\tvalid_1's l1: 0.599568\n",
      "[5000]\ttraining's l1: 0.228991\tvalid_1's l1: 0.584869\n",
      "[6000]\ttraining's l1: 0.193421\tvalid_1's l1: 0.575053\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[6000]\ttraining's l1: 0.193421\tvalid_1's l1: 0.575053\n",
      "1JHC Fold 5, logMAE: -0.5532934467850891\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.590748\tvalid_1's l1: 0.742696\n",
      "[2000]\ttraining's l1: 0.428933\tvalid_1's l1: 0.657209\n",
      "[3000]\ttraining's l1: 0.338193\tvalid_1's l1: 0.619411\n",
      "[4000]\ttraining's l1: 0.275913\tvalid_1's l1: 0.597027\n",
      "[5000]\ttraining's l1: 0.229887\tvalid_1's l1: 0.582792\n",
      "[6000]\ttraining's l1: 0.194021\tvalid_1's l1: 0.572723\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[6000]\ttraining's l1: 0.194021\tvalid_1's l1: 0.572723\n",
      "1JHC Fold 6, logMAE: -0.5573524927479913\n",
      "*** Training Model for 2JHH ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant', 'rc_A', 'rc_B', 'rc_C', 'mu', 'alpha',\n",
      "       'homo', 'lumo', 'gap', 'zpve', 'Cv', 'freqs_min', 'freqs_max',\n",
      "       'freqs_mean', 'mulliken_min', 'mulliken_max', 'mulliken_atom_0',\n",
      "       'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3', 'rc_A',\n",
      "       'rc_B', 'rc_C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'zpve', 'Cv',\n",
      "       'freqs_min', 'freqs_max', 'freqs_mean', 'mulliken_min', 'mulliken_max',\n",
      "       'mulliken_atom_0', 'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.10618\tvalid_1's l1: 0.159322\n",
      "[2000]\ttraining's l1: 0.0715496\tvalid_1's l1: 0.14556\n",
      "[3000]\ttraining's l1: 0.0525835\tvalid_1's l1: 0.140035\n",
      "[4000]\ttraining's l1: 0.0402076\tvalid_1's l1: 0.137167\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0402076\tvalid_1's l1: 0.137167\n",
      "2JHH Fold 0, logMAE: -1.9865576837843983\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.106282\tvalid_1's l1: 0.159138\n",
      "[2000]\ttraining's l1: 0.0716564\tvalid_1's l1: 0.145766\n",
      "[3000]\ttraining's l1: 0.0524559\tvalid_1's l1: 0.140229\n",
      "[4000]\ttraining's l1: 0.040039\tvalid_1's l1: 0.137384\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.040039\tvalid_1's l1: 0.137384\n",
      "2JHH Fold 1, logMAE: -1.984977344962143\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.105502\tvalid_1's l1: 0.157641\n",
      "[2000]\ttraining's l1: 0.071007\tvalid_1's l1: 0.144107\n",
      "[3000]\ttraining's l1: 0.0521167\tvalid_1's l1: 0.138803\n",
      "[4000]\ttraining's l1: 0.0398932\tvalid_1's l1: 0.136016\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0398932\tvalid_1's l1: 0.136016\n",
      "2JHH Fold 2, logMAE: -1.994979606605646\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.10614\tvalid_1's l1: 0.159645\n",
      "[2000]\ttraining's l1: 0.0712948\tvalid_1's l1: 0.145448\n",
      "[3000]\ttraining's l1: 0.0523038\tvalid_1's l1: 0.139987\n",
      "[4000]\ttraining's l1: 0.0400313\tvalid_1's l1: 0.137091\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0400313\tvalid_1's l1: 0.137091\n",
      "2JHH Fold 3, logMAE: -1.987113440114878\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.10643\tvalid_1's l1: 0.159503\n",
      "[2000]\ttraining's l1: 0.0718338\tvalid_1's l1: 0.145926\n",
      "[3000]\ttraining's l1: 0.0526042\tvalid_1's l1: 0.140162\n",
      "[4000]\ttraining's l1: 0.0402082\tvalid_1's l1: 0.137203\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0402082\tvalid_1's l1: 0.137203\n",
      "2JHH Fold 4, logMAE: -1.9862905855781323\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.10569\tvalid_1's l1: 0.160202\n",
      "[2000]\ttraining's l1: 0.0708026\tvalid_1's l1: 0.146508\n",
      "[3000]\ttraining's l1: 0.0517594\tvalid_1's l1: 0.141068\n",
      "[4000]\ttraining's l1: 0.0394736\tvalid_1's l1: 0.138129\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0394736\tvalid_1's l1: 0.138129\n",
      "2JHH Fold 5, logMAE: -1.9795697421106826\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.10635\tvalid_1's l1: 0.159095\n",
      "[2000]\ttraining's l1: 0.0717507\tvalid_1's l1: 0.145292\n",
      "[3000]\ttraining's l1: 0.0526458\tvalid_1's l1: 0.139724\n",
      "[4000]\ttraining's l1: 0.0401535\tvalid_1's l1: 0.136746\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0401535\tvalid_1's l1: 0.136746\n",
      "2JHH Fold 6, logMAE: -1.9896264662095076\n",
      "*** Training Model for 2JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant', 'rc_A', 'rc_B', 'rc_C', 'mu', 'alpha',\n",
      "       'homo', 'lumo', 'gap', 'zpve', 'Cv', 'freqs_min', 'freqs_max',\n",
      "       'freqs_mean', 'mulliken_min', 'mulliken_max', 'mulliken_atom_0',\n",
      "       'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3', 'rc_A',\n",
      "       'rc_B', 'rc_C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'zpve', 'Cv',\n",
      "       'freqs_min', 'freqs_max', 'freqs_mean', 'mulliken_min', 'mulliken_max',\n",
      "       'mulliken_atom_0', 'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.0697775\tvalid_1's l1: 0.153358\n",
      "[2000]\ttraining's l1: 0.0358028\tvalid_1's l1: 0.143668\n",
      "[3000]\ttraining's l1: 0.0203743\tvalid_1's l1: 0.140367\n",
      "[4000]\ttraining's l1: 0.0124999\tvalid_1's l1: 0.138999\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0124999\tvalid_1's l1: 0.138999\n",
      "2JHN Fold 0, logMAE: -1.9732897406699028\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.0702599\tvalid_1's l1: 0.155524\n",
      "[2000]\ttraining's l1: 0.0354179\tvalid_1's l1: 0.145813\n",
      "[3000]\ttraining's l1: 0.0201754\tvalid_1's l1: 0.142786\n",
      "[4000]\ttraining's l1: 0.0123949\tvalid_1's l1: 0.141459\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0123949\tvalid_1's l1: 0.141459\n",
      "2JHN Fold 1, logMAE: -1.955745452569189\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.068561\tvalid_1's l1: 0.152416\n",
      "[2000]\ttraining's l1: 0.0349871\tvalid_1's l1: 0.143103\n",
      "[3000]\ttraining's l1: 0.0199262\tvalid_1's l1: 0.140167\n",
      "[4000]\ttraining's l1: 0.012225\tvalid_1's l1: 0.139039\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.012225\tvalid_1's l1: 0.139039\n",
      "2JHN Fold 2, logMAE: -1.9729984152150184\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.0696185\tvalid_1's l1: 0.152718\n",
      "[2000]\ttraining's l1: 0.0352308\tvalid_1's l1: 0.143101\n",
      "[3000]\ttraining's l1: 0.0200546\tvalid_1's l1: 0.139952\n",
      "[4000]\ttraining's l1: 0.0123472\tvalid_1's l1: 0.138663\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0123472\tvalid_1's l1: 0.138663\n",
      "2JHN Fold 3, logMAE: -1.9757076048509892\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.0703954\tvalid_1's l1: 0.154308\n",
      "[2000]\ttraining's l1: 0.0359899\tvalid_1's l1: 0.144846\n",
      "[3000]\ttraining's l1: 0.0204847\tvalid_1's l1: 0.141674\n",
      "[4000]\ttraining's l1: 0.0126078\tvalid_1's l1: 0.140429\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0126078\tvalid_1's l1: 0.140429\n",
      "2JHN Fold 4, logMAE: -1.9630513670319847\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.0698427\tvalid_1's l1: 0.151016\n",
      "[2000]\ttraining's l1: 0.0354744\tvalid_1's l1: 0.141568\n",
      "[3000]\ttraining's l1: 0.0201281\tvalid_1's l1: 0.138744\n",
      "[4000]\ttraining's l1: 0.0123691\tvalid_1's l1: 0.137583\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0123691\tvalid_1's l1: 0.137583\n",
      "2JHN Fold 5, logMAE: -1.9835305561250698\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.0687441\tvalid_1's l1: 0.150983\n",
      "[2000]\ttraining's l1: 0.0349502\tvalid_1's l1: 0.141472\n",
      "[3000]\ttraining's l1: 0.0198988\tvalid_1's l1: 0.138532\n",
      "[4000]\ttraining's l1: 0.0122299\tvalid_1's l1: 0.137225\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0122299\tvalid_1's l1: 0.137225\n",
      "2JHN Fold 6, logMAE: -1.9861345075788155\n",
      "*** Training Model for 2JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant', 'rc_A', 'rc_B', 'rc_C', 'mu', 'alpha',\n",
      "       'homo', 'lumo', 'gap', 'zpve', 'Cv', 'freqs_min', 'freqs_max',\n",
      "       'freqs_mean', 'mulliken_min', 'mulliken_max', 'mulliken_atom_0',\n",
      "       'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3', 'rc_A',\n",
      "       'rc_B', 'rc_C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'zpve', 'Cv',\n",
      "       'freqs_min', 'freqs_max', 'freqs_mean', 'mulliken_min', 'mulliken_max',\n",
      "       'mulliken_atom_0', 'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.296376\tvalid_1's l1: 0.338868\n",
      "[2000]\ttraining's l1: 0.230466\tvalid_1's l1: 0.297039\n",
      "[3000]\ttraining's l1: 0.192149\tvalid_1's l1: 0.276477\n",
      "[4000]\ttraining's l1: 0.165528\tvalid_1's l1: 0.26378\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.165528\tvalid_1's l1: 0.26378\n",
      "2JHC Fold 0, logMAE: -1.3326389420695097\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.295524\tvalid_1's l1: 0.341291\n",
      "[2000]\ttraining's l1: 0.228603\tvalid_1's l1: 0.297248\n",
      "[3000]\ttraining's l1: 0.191086\tvalid_1's l1: 0.276773\n",
      "[4000]\ttraining's l1: 0.16478\tvalid_1's l1: 0.264143\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.16478\tvalid_1's l1: 0.264143\n",
      "2JHC Fold 1, logMAE: -1.3312655122773789\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.295413\tvalid_1's l1: 0.343443\n",
      "[2000]\ttraining's l1: 0.229296\tvalid_1's l1: 0.300339\n",
      "[3000]\ttraining's l1: 0.19172\tvalid_1's l1: 0.28012\n",
      "[4000]\ttraining's l1: 0.165107\tvalid_1's l1: 0.267376\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.165107\tvalid_1's l1: 0.267376\n",
      "2JHC Fold 2, logMAE: -1.3190976821987568\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.295711\tvalid_1's l1: 0.339109\n",
      "[2000]\ttraining's l1: 0.229516\tvalid_1's l1: 0.296147\n",
      "[3000]\ttraining's l1: 0.191674\tvalid_1's l1: 0.275859\n",
      "[4000]\ttraining's l1: 0.16528\tvalid_1's l1: 0.263474\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.16528\tvalid_1's l1: 0.263474\n",
      "2JHC Fold 3, logMAE: -1.3338003858663923\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.295143\tvalid_1's l1: 0.339984\n",
      "[2000]\ttraining's l1: 0.229014\tvalid_1's l1: 0.297214\n",
      "[3000]\ttraining's l1: 0.191007\tvalid_1's l1: 0.276463\n",
      "[4000]\ttraining's l1: 0.164514\tvalid_1's l1: 0.263933\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.164514\tvalid_1's l1: 0.263933\n",
      "2JHC Fold 4, logMAE: -1.3320601195384805\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.295356\tvalid_1's l1: 0.339936\n",
      "[2000]\ttraining's l1: 0.229797\tvalid_1's l1: 0.297572\n",
      "[3000]\ttraining's l1: 0.191653\tvalid_1's l1: 0.276822\n",
      "[4000]\ttraining's l1: 0.165259\tvalid_1's l1: 0.264312\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.165259\tvalid_1's l1: 0.264312\n",
      "2JHC Fold 5, logMAE: -1.330626248554234\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.296127\tvalid_1's l1: 0.342403\n",
      "[2000]\ttraining's l1: 0.229778\tvalid_1's l1: 0.299349\n",
      "[3000]\ttraining's l1: 0.191897\tvalid_1's l1: 0.278897\n",
      "[4000]\ttraining's l1: 0.165458\tvalid_1's l1: 0.266293\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.165458\tvalid_1's l1: 0.266293\n",
      "2JHC Fold 6, logMAE: -1.3231564949625538\n",
      "*** Training Model for 3JHH ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant', 'rc_A', 'rc_B', 'rc_C', 'mu', 'alpha',\n",
      "       'homo', 'lumo', 'gap', 'zpve', 'Cv', 'freqs_min', 'freqs_max',\n",
      "       'freqs_mean', 'mulliken_min', 'mulliken_max', 'mulliken_atom_0',\n",
      "       'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3', 'rc_A',\n",
      "       'rc_B', 'rc_C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'zpve', 'Cv',\n",
      "       'freqs_min', 'freqs_max', 'freqs_mean', 'mulliken_min', 'mulliken_max',\n",
      "       'mulliken_atom_0', 'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.154713\tvalid_1's l1: 0.196008\n",
      "[2000]\ttraining's l1: 0.112152\tvalid_1's l1: 0.174118\n",
      "[3000]\ttraining's l1: 0.0880992\tvalid_1's l1: 0.164674\n",
      "[4000]\ttraining's l1: 0.0717372\tvalid_1's l1: 0.159329\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0717372\tvalid_1's l1: 0.159329\n",
      "3JHH Fold 0, logMAE: -1.83678207865668\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.154029\tvalid_1's l1: 0.197163\n",
      "[2000]\ttraining's l1: 0.11191\tvalid_1's l1: 0.175824\n",
      "[3000]\ttraining's l1: 0.0879726\tvalid_1's l1: 0.166277\n",
      "[4000]\ttraining's l1: 0.0716015\tvalid_1's l1: 0.160924\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0716015\tvalid_1's l1: 0.160924\n",
      "3JHH Fold 1, logMAE: -1.8268241329532529\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.155061\tvalid_1's l1: 0.197353\n",
      "[2000]\ttraining's l1: 0.112592\tvalid_1's l1: 0.17561\n",
      "[3000]\ttraining's l1: 0.0883725\tvalid_1's l1: 0.166207\n",
      "[4000]\ttraining's l1: 0.0718706\tvalid_1's l1: 0.16086\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0718706\tvalid_1's l1: 0.16086\n",
      "3JHH Fold 2, logMAE: -1.8272183497161025\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.154405\tvalid_1's l1: 0.196731\n",
      "[2000]\ttraining's l1: 0.111861\tvalid_1's l1: 0.174952\n",
      "[3000]\ttraining's l1: 0.0877982\tvalid_1's l1: 0.16561\n",
      "[4000]\ttraining's l1: 0.0714178\tvalid_1's l1: 0.160228\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0714178\tvalid_1's l1: 0.160228\n",
      "3JHH Fold 3, logMAE: -1.831156887726738\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.154108\tvalid_1's l1: 0.195498\n",
      "[2000]\ttraining's l1: 0.111721\tvalid_1's l1: 0.174013\n",
      "[3000]\ttraining's l1: 0.0878129\tvalid_1's l1: 0.164947\n",
      "[4000]\ttraining's l1: 0.0714254\tvalid_1's l1: 0.159679\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0714254\tvalid_1's l1: 0.159679\n",
      "3JHH Fold 4, logMAE: -1.8345914513945203\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.154829\tvalid_1's l1: 0.199243\n",
      "[2000]\ttraining's l1: 0.112253\tvalid_1's l1: 0.177059\n",
      "[3000]\ttraining's l1: 0.0882876\tvalid_1's l1: 0.16741\n",
      "[4000]\ttraining's l1: 0.0718031\tvalid_1's l1: 0.161832\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0718031\tvalid_1's l1: 0.161832\n",
      "3JHH Fold 5, logMAE: -1.8211986521151193\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.15524\tvalid_1's l1: 0.198226\n",
      "[2000]\ttraining's l1: 0.112391\tvalid_1's l1: 0.176238\n",
      "[3000]\ttraining's l1: 0.0883158\tvalid_1's l1: 0.166775\n",
      "[4000]\ttraining's l1: 0.0718262\tvalid_1's l1: 0.161361\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0718262\tvalid_1's l1: 0.161361\n",
      "3JHH Fold 6, logMAE: -1.824109809337815\n",
      "*** Training Model for 3JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant', 'rc_A', 'rc_B', 'rc_C', 'mu', 'alpha',\n",
      "       'homo', 'lumo', 'gap', 'zpve', 'Cv', 'freqs_min', 'freqs_max',\n",
      "       'freqs_mean', 'mulliken_min', 'mulliken_max', 'mulliken_atom_0',\n",
      "       'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3', 'rc_A',\n",
      "       'rc_B', 'rc_C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'zpve', 'Cv',\n",
      "       'freqs_min', 'freqs_max', 'freqs_mean', 'mulliken_min', 'mulliken_max',\n",
      "       'mulliken_atom_0', 'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.350931\tvalid_1's l1: 0.387783\n",
      "[2000]\ttraining's l1: 0.279479\tvalid_1's l1: 0.33742\n",
      "[3000]\ttraining's l1: 0.238529\tvalid_1's l1: 0.312663\n",
      "[4000]\ttraining's l1: 0.209811\tvalid_1's l1: 0.297464\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.209811\tvalid_1's l1: 0.297464\n",
      "3JHC Fold 0, logMAE: -1.212461386305989\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.351665\tvalid_1's l1: 0.388745\n",
      "[2000]\ttraining's l1: 0.279624\tvalid_1's l1: 0.337429\n",
      "[3000]\ttraining's l1: 0.238714\tvalid_1's l1: 0.312779\n",
      "[4000]\ttraining's l1: 0.210274\tvalid_1's l1: 0.29794\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.210274\tvalid_1's l1: 0.29794\n",
      "3JHC Fold 1, logMAE: -1.2108629575056697\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.348725\tvalid_1's l1: 0.385053\n",
      "[2000]\ttraining's l1: 0.278674\tvalid_1's l1: 0.335811\n",
      "[3000]\ttraining's l1: 0.237872\tvalid_1's l1: 0.311222\n",
      "[4000]\ttraining's l1: 0.209288\tvalid_1's l1: 0.296326\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.209288\tvalid_1's l1: 0.296326\n",
      "3JHC Fold 2, logMAE: -1.2162959900027446\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.349414\tvalid_1's l1: 0.386272\n",
      "[2000]\ttraining's l1: 0.278438\tvalid_1's l1: 0.336092\n",
      "[3000]\ttraining's l1: 0.237785\tvalid_1's l1: 0.311463\n",
      "[4000]\ttraining's l1: 0.20955\tvalid_1's l1: 0.296785\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.20955\tvalid_1's l1: 0.296785\n",
      "3JHC Fold 3, logMAE: -1.2147479685934819\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.350349\tvalid_1's l1: 0.387346\n",
      "[2000]\ttraining's l1: 0.279461\tvalid_1's l1: 0.337121\n",
      "[3000]\ttraining's l1: 0.23861\tvalid_1's l1: 0.312581\n",
      "[4000]\ttraining's l1: 0.209917\tvalid_1's l1: 0.297468\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.209917\tvalid_1's l1: 0.297468\n",
      "3JHC Fold 4, logMAE: -1.2124497449263143\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.349606\tvalid_1's l1: 0.385094\n",
      "[2000]\ttraining's l1: 0.278757\tvalid_1's l1: 0.334999\n",
      "[3000]\ttraining's l1: 0.238251\tvalid_1's l1: 0.310674\n",
      "[4000]\ttraining's l1: 0.209527\tvalid_1's l1: 0.295445\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.209527\tvalid_1's l1: 0.295445\n",
      "3JHC Fold 5, logMAE: -1.219273927900658\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.350512\tvalid_1's l1: 0.387594\n",
      "[2000]\ttraining's l1: 0.279512\tvalid_1's l1: 0.337486\n",
      "[3000]\ttraining's l1: 0.239377\tvalid_1's l1: 0.31334\n",
      "[4000]\ttraining's l1: 0.210669\tvalid_1's l1: 0.298209\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.210669\tvalid_1's l1: 0.298209\n",
      "3JHC Fold 6, logMAE: -1.2099622282042979\n",
      "*** Training Model for 3JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant', 'rc_A', 'rc_B', 'rc_C', 'mu', 'alpha',\n",
      "       'homo', 'lumo', 'gap', 'zpve', 'Cv', 'freqs_min', 'freqs_max',\n",
      "       'freqs_mean', 'mulliken_min', 'mulliken_max', 'mulliken_atom_0',\n",
      "       'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3', 'rc_A',\n",
      "       'rc_B', 'rc_C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'zpve', 'Cv',\n",
      "       'freqs_min', 'freqs_max', 'freqs_mean', 'mulliken_min', 'mulliken_max',\n",
      "       'mulliken_atom_0', 'mulliken_atom_1'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.0627723\tvalid_1's l1: 0.120139\n",
      "[2000]\ttraining's l1: 0.0351317\tvalid_1's l1: 0.111486\n",
      "[3000]\ttraining's l1: 0.0219645\tvalid_1's l1: 0.108555\n",
      "[4000]\ttraining's l1: 0.014576\tvalid_1's l1: 0.107205\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.014576\tvalid_1's l1: 0.107205\n",
      "3JHN Fold 0, logMAE: -2.2330116430068427\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.0631068\tvalid_1's l1: 0.120021\n",
      "[2000]\ttraining's l1: 0.0352844\tvalid_1's l1: 0.111687\n",
      "[3000]\ttraining's l1: 0.0220157\tvalid_1's l1: 0.108699\n",
      "[4000]\ttraining's l1: 0.0146084\tvalid_1's l1: 0.107298\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0146084\tvalid_1's l1: 0.107298\n",
      "3JHN Fold 1, logMAE: -2.2321456123963506\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.0631912\tvalid_1's l1: 0.12153\n",
      "[2000]\ttraining's l1: 0.0352608\tvalid_1's l1: 0.113126\n",
      "[3000]\ttraining's l1: 0.0220268\tvalid_1's l1: 0.110236\n",
      "[4000]\ttraining's l1: 0.0146219\tvalid_1's l1: 0.108875\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0146219\tvalid_1's l1: 0.108875\n",
      "3JHN Fold 2, logMAE: -2.2175527873724983\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.0625859\tvalid_1's l1: 0.120919\n",
      "[2000]\ttraining's l1: 0.0350504\tvalid_1's l1: 0.112699\n",
      "[3000]\ttraining's l1: 0.0219306\tvalid_1's l1: 0.109701\n",
      "[4000]\ttraining's l1: 0.014608\tvalid_1's l1: 0.108328\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.014608\tvalid_1's l1: 0.108328\n",
      "3JHN Fold 3, logMAE: -2.222591156870414\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.0629493\tvalid_1's l1: 0.120092\n",
      "[2000]\ttraining's l1: 0.0351315\tvalid_1's l1: 0.1116\n",
      "[3000]\ttraining's l1: 0.0218933\tvalid_1's l1: 0.108598\n",
      "[4000]\ttraining's l1: 0.0145133\tvalid_1's l1: 0.107167\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0145133\tvalid_1's l1: 0.107167\n",
      "3JHN Fold 4, logMAE: -2.233368916191027\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.062614\tvalid_1's l1: 0.120933\n",
      "[2000]\ttraining's l1: 0.035069\tvalid_1's l1: 0.112755\n",
      "[3000]\ttraining's l1: 0.0218971\tvalid_1's l1: 0.109838\n",
      "[4000]\ttraining's l1: 0.0145697\tvalid_1's l1: 0.10838\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0145697\tvalid_1's l1: 0.10838\n",
      "3JHN Fold 5, logMAE: -2.2221109162619332\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.0625066\tvalid_1's l1: 0.12212\n",
      "[2000]\ttraining's l1: 0.0350915\tvalid_1's l1: 0.113456\n",
      "[3000]\ttraining's l1: 0.0219511\tvalid_1's l1: 0.110509\n",
      "[4000]\ttraining's l1: 0.0146394\tvalid_1's l1: 0.109113\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's l1: 0.0146394\tvalid_1's l1: 0.109113\n",
      "3JHN Fold 6, logMAE: -2.2153723041293625\n"
     ]
    }
   ],
   "source": [
    "# 模型的n_atoms个数设置\n",
    "model_params = {\n",
    "    '1JHN': 10,\n",
    "    '1JHC': 13,\n",
    "    '2JHH': 10,\n",
    "    '2JHN': 10,\n",
    "    '2JHC': 10,\n",
    "    '3JHH': 10,\n",
    "    '3JHC': 10,\n",
    "    '3JHN': 10\n",
    "}\n",
    "# 模型的深度设置\n",
    "model_depth=\\\n",
    "{\n",
    "    '1JHN': 10,\n",
    "    '1JHC': 11,\n",
    "    '2JHH': 10,\n",
    "    '2JHN': 10,\n",
    "    '2JHC': 10,\n",
    "    '3JHH': 10,\n",
    "    '3JHC': 10,\n",
    "    '3JHN': 10\n",
    "}\n",
    "# 7折交叉验证\n",
    "N_FOLDS = 7\n",
    "submission = submission_csv.copy()\n",
    "oof_submission=train_csv[['type','scalar_coupling_constant']].copy()\n",
    "oof_submission['scalar_coupling_constant']=0\n",
    "\n",
    "# 对于每种类型都进行训练\n",
    "cv_scores = {}\n",
    "for coupling_type in model_params.keys():\n",
    "    cv_score = train_and_predict_for_one_coupling_type(\n",
    "        coupling_type, submission,oof_submission,n_atoms=model_params[coupling_type], n_folds=N_FOLDS,n_depth=model_depth[coupling_type],random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_submission.head()\n",
    "oof_submission.to_csv('lgb_oof.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [type, cv_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'type': list(cv_scores.keys()), 'cv_score': list(cv_scores.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(cv_scores.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[submission['scalar_coupling_constant'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4658147</th>\n",
       "      <td>18.351702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658148</th>\n",
       "      <td>152.206772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658149</th>\n",
       "      <td>10.194800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658150</th>\n",
       "      <td>152.206772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658151</th>\n",
       "      <td>18.351702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658152</th>\n",
       "      <td>92.467049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658153</th>\n",
       "      <td>2.697306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658154</th>\n",
       "      <td>-8.251464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658155</th>\n",
       "      <td>-9.931295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658156</th>\n",
       "      <td>92.461830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scalar_coupling_constant\n",
       "id                               \n",
       "4658147  18.351702               \n",
       "4658148  152.206772              \n",
       "4658149  10.194800               \n",
       "4658150  152.206772              \n",
       "4658151  18.351702               \n",
       "4658152  92.467049               \n",
       "4658153  2.697306                \n",
       "4658154 -8.251464                \n",
       "4658155 -9.931295                \n",
       "4658156  92.461830               "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提交最终结果\n",
    "submission.to_csv(f'{SUBMISSIONS_PATH}/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Room for improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
